\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{film-grain-rendering}
\@writefile{toc}{\contentsline {title}{ Sillystill: Recreating the Look of Cinestill-800T using Deep Learning }{1}{chapter.1}\protected@file@percent }
\@writefile{toc}{\authcount {1}}
\@writefile{toc}{\contentsline {author}{Mika Senghaas \hskip 1em\relax Annamira O'Toole \hskip 1em\relax Pierre Lardet}{1}{chapter.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1.1}\protected@file@percent }
\newlabel{sec:introduction}{{1}{1}{Introduction}{section.1.1}{}}
\newlabel{sec:introduction@cref}{{[section][1][]1}{[1][1][]1}}
\@writefile{brf}{\backcite{film-grain-rendering}{{1}{1}{section.1.1}}}
\citation{conditionalgan}
\citation{cyclicgan}
\citation{image-super-resolution-with-deep-networks,accurate-image-super-resolution,resolution-perceptual-losses}
\citation{gan-photo-realistic-super-resolution,esrgan-super-resolution}
\citation{pulse-gan-perceptual-super-resolution,recovering-texture-super-resolution}
\citation{gan-progressive-stability-resolution}
\citation{gan-style-based-resolution}
\citation{zoom-to-learn}
\citation{contextual-loss}
\citation{large-scale-colorisation}
\citation{intrinsic-colorisation}
\citation{deep-colorisation}
\@writefile{toc}{\contentsline {section}{\numberline {2}Literature Review}{2}{section.1.2}\protected@file@percent }
\newlabel{sec:literature-review}{{2}{2}{Literature Review}{section.1.2}{}}
\newlabel{sec:literature-review@cref}{{[section][2][]2}{[1][2][]2}}
\@writefile{brf}{\backcite{conditionalgan}{{2}{2}{section.1.2}}}
\@writefile{brf}{\backcite{cyclicgan}{{2}{2}{section.1.2}}}
\@writefile{brf}{\backcite{image-super-resolution-with-deep-networks,accurate-image-super-resolution,resolution-perceptual-losses}{{2}{2}{section.1.2}}}
\@writefile{brf}{\backcite{gan-photo-realistic-super-resolution, esrgan-super-resolution}{{2}{2}{section.1.2}}}
\@writefile{brf}{\backcite{pulse-gan-perceptual-super-resolution,recovering-texture-super-resolution}{{2}{2}{section.1.2}}}
\@writefile{brf}{\backcite{gan-progressive-stability-resolution}{{2}{2}{section.1.2}}}
\@writefile{brf}{\backcite{gan-style-based-resolution}{{2}{2}{section.1.2}}}
\@writefile{brf}{\backcite{zoom-to-learn}{{2}{2}{section.1.2}}}
\@writefile{brf}{\backcite{contextual-loss}{{2}{2}{section.1.2}}}
\citation{raw-to-raw}
\citation{image-style-transfer,scaling-painting-style-transfer}
\citation{deep-photo-style-transfer}
\citation{resolution-perceptual-losses}
\citation{arbitrary-style-transfer}
\citation{dslr-quality}
\citation{vgg}
\citation{dslr-quality}
\@writefile{brf}{\backcite{large-scale-colorisation}{{3}{2}{section.1.2}}}
\@writefile{brf}{\backcite{intrinsic-colorisation}{{3}{2}{section.1.2}}}
\@writefile{brf}{\backcite{deep-colorisation}{{3}{2}{section.1.2}}}
\@writefile{brf}{\backcite{raw-to-raw}{{3}{2}{section.1.2}}}
\@writefile{brf}{\backcite{image-style-transfer, scaling-painting-style-transfer}{{3}{2}{section.1.2}}}
\@writefile{brf}{\backcite{deep-photo-style-transfer}{{3}{2}{section.1.2}}}
\@writefile{brf}{\backcite{resolution-perceptual-losses}{{3}{2}{section.1.2}}}
\@writefile{brf}{\backcite{arbitrary-style-transfer}{{3}{2}{section.1.2}}}
\@writefile{brf}{\backcite{dslr-quality}{{3}{2}{section.1.2}}}
\@writefile{brf}{\backcite{vgg}{{3}{2}{section.1.2}}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Implementation}{3}{section.1.3}\protected@file@percent }
\newlabel{sec:implementation}{{3}{3}{Implementation}{section.1.3}{}}
\newlabel{sec:implementation@cref}{{[section][3][]3}{[1][3][]3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Data Collection and Preprocessing}{3}{subsection.1.3.1}\protected@file@percent }
\newlabel{subsec:data}{{3.1}{3}{Data Collection and Preprocessing}{subsection.1.3.1}{}}
\newlabel{subsec:data@cref}{{[subsection][1][3]3.1}{[1][3][]3}}
\newlabel{subsubsec:data-collection}{{3.1}{3}{Data Collection and Preprocessing}{subsection.1.3.1}{}}
\newlabel{subsubsec:data-collection@cref}{{[subsection][1][3]3.1}{[1][3][]3}}
\@writefile{brf}{\backcite{dslr-quality}{{3}{3.1}{subsection.1.3.1}}}
\citation{opencv}
\citation{orb}
\citation{flann}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Camera Setup.}}{4}{table.caption.2}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{tab:cameras}{{1}{4}{Camera Setup}{table.caption.2}{}}
\newlabel{tab:cameras@cref}{{[table][1][]1}{[1][4][]4}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces \textbf  {Raw Paired Image Dataset.} Examples of raw image pairs from the dataset. A column shows a single scene captured with a digital camera (top) and a film camera (bottom). The images show a wide range of scenes and visual effects.}}{4}{figure.caption.3}\protected@file@percent }
\newlabel{fig:raw-dataset}{{1}{4}{\textbf {Raw Paired Image Dataset.} Examples of raw image pairs from the dataset. A column shows a single scene captured with a digital camera (top) and a film camera (bottom). The images show a wide range of scenes and visual effects}{figure.caption.3}{}}
\newlabel{fig:raw-dataset@cref}{{[figure][1][]1}{[1][4][]4}}
\newlabel{subsubsec:preprocessing}{{3.1}{4}{Data Preprocessing}{section*.4}{}}
\newlabel{subsubsec:preprocessing@cref}{{[subsection][1][3]3.1}{[1][4][]4}}
\@writefile{brf}{\backcite{opencv}{{4}{3.1}{section*.4}}}
\@writefile{brf}{\backcite{orb}{{4}{3.1}{section*.4}}}
\@writefile{brf}{\backcite{flann}{{4}{3.1}{section*.4}}}
\citation{unet}
\citation{raw-to-raw}
\citation{perceptual-losses-style-transfer}
\citation{dslr-quality}
\citation{unet,dslr-quality,raw-to-raw}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces \textbf  {Dataset Preprocessing.} Example of a raw and processed image pair. We can see the luminance alignment in the film image (a) and the spatial alignment in the digital image (b).}}{5}{figure.caption.5}\protected@file@percent }
\newlabel{fig:data-preprocessing}{{2}{5}{\textbf {Dataset Preprocessing.} Example of a raw and processed image pair. We can see the luminance alignment in the film image (a) and the spatial alignment in the digital image (b)}{figure.caption.5}{}}
\newlabel{fig:data-preprocessing@cref}{{[figure][2][]2}{[1][4][]5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Model}{5}{subsection.1.3.2}\protected@file@percent }
\newlabel{subsec:model}{{3.2}{5}{Model}{subsection.1.3.2}{}}
\newlabel{subsec:model@cref}{{[subsection][2][3]3.2}{[1][5][]5}}
\@writefile{brf}{\backcite{unet}{{5}{3.2}{subsection.1.3.2}}}
\@writefile{brf}{\backcite{raw-to-raw}{{5}{3.2}{subsection.1.3.2}}}
\@writefile{brf}{\backcite{perceptual-losses-style-transfer}{{5}{3.2}{subsection.1.3.2}}}
\@writefile{brf}{\backcite{dslr-quality}{{5}{3.2}{subsection.1.3.2}}}
\@writefile{brf}{\backcite{unet,dslr-quality,raw-to-raw}{{5}{3.2}{subsection.1.3.2}}}
\citation{vgg}
\citation{dslr-quality}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Loss Functions}{6}{subsection.1.3.3}\protected@file@percent }
\newlabel{subsec:loss-functions}{{3.3}{6}{Loss Functions}{subsection.1.3.3}{}}
\newlabel{subsec:loss-functions@cref}{{[subsection][3][3]3.3}{[1][6][]6}}
\newlabel{eq:mse}{{1}{6}{Loss Functions}{equation.1.3.1}{}}
\newlabel{eq:mse@cref}{{[equation][1][]1}{[1][6][]6}}
\newlabel{eq:mae}{{2}{6}{Loss Functions}{equation.1.3.2}{}}
\newlabel{eq:mae@cref}{{[equation][2][]2}{[1][6][]6}}
\@writefile{brf}{\backcite{vgg}{{6}{3.3}{equation.1.3.2}}}
\newlabel{eq:vgg}{{3}{6}{Loss Functions}{equation.1.3.3}{}}
\newlabel{eq:vgg@cref}{{[equation][3][]3}{[1][6][]6}}
\@writefile{brf}{\backcite{dslr-quality}{{6}{3.3}{equation.1.3.3}}}
\newlabel{eq:color}{{4}{7}{Loss Functions}{equation.1.3.4}{}}
\newlabel{eq:color@cref}{{[equation][4][]4}{[1][7][]7}}
\newlabel{eq:tv-rel}{{5}{7}{Loss Functions}{equation.1.3.5}{}}
\newlabel{eq:tv-rel@cref}{{[equation][5][]5}{[1][7][]7}}
\newlabel{eq:combined-loss}{{6}{7}{Loss Functions}{equation.1.3.6}{}}
\newlabel{eq:combined-loss@cref}{{[equation][6][]6}{[1][7][]7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Experiments}{7}{subsection.1.3.4}\protected@file@percent }
\newlabel{subsec:experiments}{{3.4}{7}{Experiments}{subsection.1.3.4}{}}
\newlabel{subsec:experiments@cref}{{[subsection][4][3]3.4}{[1][7][]7}}
\citation{LPIPS}
\citation{PieAPP}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces \textbf  {Training Overview.} We train our model on paired digital-film images.}}{8}{figure.caption.6}\protected@file@percent }
\newlabel{fig:training-overview}{{3}{8}{\textbf {Training Overview.} We train our model on paired digital-film images}{figure.caption.6}{}}
\newlabel{fig:training-overview@cref}{{[figure][3][]3}{[1][7][]8}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5}Evaluation}{8}{subsection.1.3.5}\protected@file@percent }
\newlabel{subsec:evaluation}{{3.5}{8}{Evaluation}{subsection.1.3.5}{}}
\newlabel{subsec:evaluation@cref}{{[subsection][5][3]3.5}{[1][8][]8}}
\@writefile{brf}{\backcite{LPIPS}{{9}{3.5}{subsection.1.3.5}}}
\@writefile{brf}{\backcite{PieAPP}{{9}{3.5}{subsection.1.3.5}}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Results}{9}{section.1.4}\protected@file@percent }
\newlabel{sec:results}{{4}{9}{Results}{section.1.4}{}}
\newlabel{sec:results@cref}{{[section][4][]4}{[1][9][]9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Single Image Results}{9}{subsection.1.4.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces \textbf  {Single Image Select Samples.} Outputs from select loss functions and configurations of noise and resizing. We see that the best performing model is MSE/VGG with resizing, which produces the best colour effect. We also see that LPIPS scores are inconsistent with SSIM and with perception as we can intuitively see that MSE-VGG and MSE are better predicitions than the baseline and TV-Rel.}}{9}{figure.caption.7}\protected@file@percent }
\newlabel{fig:single-image-samples}{{4}{9}{\textbf {Single Image Select Samples.} Outputs from select loss functions and configurations of noise and resizing. We see that the best performing model is MSE/VGG with resizing, which produces the best colour effect. We also see that LPIPS scores are inconsistent with SSIM and with perception as we can intuitively see that MSE-VGG and MSE are better predicitions than the baseline and TV-Rel}{figure.caption.7}{}}
\newlabel{fig:single-image-samples@cref}{{[figure][4][]4}{[1][9][]9}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces  \textbf  {Single Image Losses.}  Results for each loss configuration with and without noise and no resizing. }}{10}{table.caption.8}\protected@file@percent }
\newlabel{tab:single-image-losses}{{2}{10}{\textbf {Single Image Losses.} \\Results for each loss configuration with and without noise and no resizing}{table.caption.8}{}}
\newlabel{tab:single-image-losses@cref}{{[table][2][]2}{[1][9][]10}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces  \textbf  {Single Image Resizing.}   Effect of resizing the cropped patches on select losses (no noise). }}{10}{table.caption.12}\protected@file@percent }
\newlabel{tab:single-image-resize}{{3}{10}{\textbf {Single Image Resizing.} \\ Effect of resizing the cropped patches on select losses (no noise)}{table.caption.12}{}}
\newlabel{tab:single-image-resize@cref}{{[table][3][]3}{[1][10][]10}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces \textbf  {Single Image Noise Comparison.} Outputs from select models without noise (above) and with noise (below), no resizing. We see that when we feed noise into the model, the model learns to produce some variation, especially when the loss contains a feature-based metric like VGG. However, the grain is far from the desired effect.}}{11}{figure.caption.9}\protected@file@percent }
\newlabel{fig:single-image-noise-no-noise}{{5}{11}{\textbf {Single Image Noise Comparison.} Outputs from select models without noise (above) and with noise (below), no resizing. We see that when we feed noise into the model, the model learns to produce some variation, especially when the loss contains a feature-based metric like VGG. However, the grain is far from the desired effect}{figure.caption.9}{}}
\newlabel{fig:single-image-noise-no-noise@cref}{{[figure][5][]5}{[1][9][]11}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Full Dataset Results}{11}{subsection.1.4.2}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces \textbf  {Full Dataset Results.}   Comparison of best performing losses and configurations on the full dataset.}}{11}{table.caption.13}\protected@file@percent }
\newlabel{tab:full-data-results}{{4}{11}{\textbf {Full Dataset Results.} \\ Comparison of best performing losses and configurations on the full dataset}{table.caption.13}{}}
\newlabel{tab:full-data-results@cref}{{[table][4][]4}{[1][11][]11}}
\citation{dslr-quality}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces \textbf  {Single Image Resizing.} Outputs from MSE and MSE/VGG with and without resizing, and then with resizing and with and without noise. We see that resizing improves the colour effect, but the grain effect is not as strong as in the single image experiments.}}{12}{figure.caption.10}\protected@file@percent }
\newlabel{fig:single-image-resize}{{6}{12}{\textbf {Single Image Resizing.} Outputs from MSE and MSE/VGG with and without resizing, and then with resizing and with and without noise. We see that resizing improves the colour effect, but the grain effect is not as strong as in the single image experiments}{figure.caption.10}{}}
\newlabel{fig:single-image-resize@cref}{{[figure][6][]6}{[1][10][]12}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces \textbf  {Single Image Resizing with Noise.} Outputs from MSE and MSE/VGG with and without noise and resizing. We see that similar grain is still produced even through resizing.}}{12}{figure.caption.11}\protected@file@percent }
\newlabel{fig:single-image-resize-noise}{{7}{12}{\textbf {Single Image Resizing with Noise.} Outputs from MSE and MSE/VGG with and without noise and resizing. We see that similar grain is still produced even through resizing}{figure.caption.11}{}}
\newlabel{fig:single-image-resize-noise@cref}{{[figure][7][]7}{[1][10][]12}}
\@writefile{brf}{\backcite{dslr-quality}{{12}{4.2}{figure.caption.16}}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces \textbf  {Full Dataset Select Samples.} Outputs from select models on the full dataset. We see that the best performing model is MSE/VGG with resizing, which produces the best colour effect. We also see that the grain effect is not as strong as in the single image experiments.}}{13}{figure.caption.14}\protected@file@percent }
\newlabel{fig:full-data-results}{{8}{13}{\textbf {Full Dataset Select Samples.} Outputs from select models on the full dataset. We see that the best performing model is MSE/VGG with resizing, which produces the best colour effect. We also see that the grain effect is not as strong as in the single image experiments}{figure.caption.14}{}}
\newlabel{fig:full-data-results@cref}{{[figure][8][]8}{[1][12][]13}}
\@writefile{lot}{\contentsline {table}{\numberline {5}{\ignorespaces \textbf  {Full Dataset Noise and Resizing.}   Comparison of MSE and MSE/VGG with and without noise and resizing.}}{13}{table.caption.15}\protected@file@percent }
\newlabel{tab:full-data-resize-noise}{{5}{13}{\textbf {Full Dataset Noise and Resizing.} \\ Comparison of MSE and MSE/VGG with and without noise and resizing}{table.caption.15}{}}
\newlabel{tab:full-data-resize-noise@cref}{{[table][5][]5}{[1][12][]13}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces \textbf  {Full Dataset Grain Comparison.} Predictions for a patch of sky from select loss functions, all with noise. Similarly to the single image experiments, the models with losses that target some noise produce a more visually pleasing result. The best visual result is produced by Color/VGG/TV-Rel although this is still far from the true grain texture.}}{13}{figure.caption.16}\protected@file@percent }
\newlabel{fig:full-data-grain}{{9}{13}{\textbf {Full Dataset Grain Comparison.} Predictions for a patch of sky from select loss functions, all with noise. Similarly to the single image experiments, the models with losses that target some noise produce a more visually pleasing result. The best visual result is produced by Color/VGG/TV-Rel although this is still far from the true grain texture}{figure.caption.16}{}}
\newlabel{fig:full-data-grain@cref}{{[figure][9][]9}{[1][12][]13}}
\citation{glcm}
\citation{dslr-quality}
\citation{raw-to-raw}
\citation{zoom-to-learn}
\@writefile{toc}{\contentsline {section}{\numberline {5}Conclusion}{14}{section.1.5}\protected@file@percent }
\newlabel{sec:conclusion}{{5}{14}{Conclusion}{section.1.5}{}}
\newlabel{sec:conclusion@cref}{{[section][5][]5}{[1][14][]14}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Further Work}{14}{section.1.6}\protected@file@percent }
\newlabel{sec:further-work}{{6}{14}{Further Work}{section.1.6}{}}
\newlabel{sec:further-work@cref}{{[section][6][]6}{[1][14][]14}}
\@writefile{brf}{\backcite{glcm}{{15}{6}{section.1.6}}}
\@writefile{brf}{\backcite{dslr-quality}{{15}{6}{section.1.6}}}
\@writefile{brf}{\backcite{raw-to-raw}{{15}{6}{section.1.6}}}
\@writefile{brf}{\backcite{zoom-to-learn}{{15}{6}{section.1.6}}}
\bibstyle{splncs04}
\bibdata{main}
\bibcite{raw-to-raw}{1}
\bibcite{opencv}{2}
\bibcite{deep-colorisation}{3}
\bibcite{large-scale-colorisation}{4}
\bibcite{image-super-resolution-with-deep-networks}{5}
\bibcite{scaling-painting-style-transfer}{6}
\bibcite{image-style-transfer}{7}
\bibcite{arbitrary-style-transfer}{8}
\bibcite{dslr-quality}{9}
\bibcite{conditionalgan}{10}
\bibcite{resolution-perceptual-losses}{11}
\bibcite{perceptual-losses-style-transfer}{12}
\bibcite{gan-progressive-stability-resolution}{13}
\bibcite{gan-style-based-resolution}{14}
\bibcite{accurate-image-super-resolution}{15}
\bibcite{gan-photo-realistic-super-resolution}{16}
\bibcite{intrinsic-colorisation}{17}
\bibcite{deep-photo-style-transfer}{18}
\bibcite{contextual-loss}{19}
\bibcite{pulse-gan-perceptual-super-resolution}{20}
\bibcite{flann}{21}
\bibcite{film-grain-rendering}{22}
\bibcite{PieAPP}{23}
\bibcite{unet}{24}
\bibcite{orb}{25}
\bibcite{vgg}{26}
\bibcite{recovering-texture-super-resolution}{27}
\bibcite{esrgan-super-resolution}{28}
\bibcite{glcm}{29}
\bibcite{LPIPS}{30}
\bibcite{zoom-to-learn}{31}
\bibcite{cyclicgan}{32}
\@writefile{toc}{\contentsline {section}{\numberline {7}Appendix}{18}{section.1.7}\protected@file@percent }
\newlabel{sec:appendix}{{7}{18}{Appendix}{section.1.7}{}}
\newlabel{sec:appendix@cref}{{[section][7][]7}{[1][18][]18}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1}Code Documentation}{18}{subsection.1.7.1}\protected@file@percent }
\newlabel{sec:code-documentation}{{7.1}{18}{Code Documentation}{subsection.1.7.1}{}}
\newlabel{sec:code-documentation@cref}{{[subsection][1][7]7.1}{[1][18][]18}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2}All Results}{19}{subsection.1.7.2}\protected@file@percent }
\newlabel{sec:all-results}{{7.2}{19}{All Results}{subsection.1.7.2}{}}
\newlabel{sec:all-results@cref}{{[subsection][2][7]7.2}{[1][19][]19}}
\@writefile{lot}{\contentsline {table}{\numberline {6}{\ignorespaces  \textbf  {Single Image.} All Results}}{19}{table.caption.18}\protected@file@percent }
\newlabel{tab:all-single-image-results}{{6}{19}{\textbf {Single Image.} All Results}{table.caption.18}{}}
\newlabel{tab:all-single-image-results@cref}{{[table][6][]6}{[1][19][]19}}
\@writefile{lot}{\contentsline {table}{\numberline {7}{\ignorespaces \textbf  {Full Dataset.} All results}}{19}{table.caption.19}\protected@file@percent }
\newlabel{tab:all-full-dataset-results}{{7}{19}{\textbf {Full Dataset.} All results}{table.caption.19}{}}
\newlabel{tab:all-full-dataset-results@cref}{{[table][7][]7}{[1][19][]19}}
\gdef \@abspage@last{19}
