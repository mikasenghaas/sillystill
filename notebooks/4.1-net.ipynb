{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ¤– Models\n",
    "\n",
    "This notebook shows how to use the various network architectures defined in this project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "---\n",
    "\n",
    "Let's install some necessary dependencies and set global variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autoroot\n",
    "import autorootcwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch\n",
    "from hydra import compose, initialize\n",
    "from hydra.utils import instantiate\n",
    "\n",
    "from src.models.net import FFNet, ConvNet, UNet, AutoTranslateNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FFNet\n",
    "\n",
    "The `FFNet` is a simple linear encoder-decoder network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise `FFNet`\n",
    "net = FFNet(input_output_size=32*32, hidden_dims=[256, 128])\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward pass\n",
    "x = torch.randn(1, 1, 32, 32)\n",
    "y = net(x)\n",
    "\n",
    "assert x.shape == y.shape\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ConvNet\n",
    "\n",
    "\n",
    "A simple convolutional encoder-decoder neural network (without skip connections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise `ConvNet`\n",
    "net = ConvNet(input_output_channels=3, hidden_channels=[64, 128, 256])\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward pass\n",
    "x = torch.randn(1, 3, 32, 32)\n",
    "y = net(x)\n",
    "\n",
    "assert x.shape == y.shape\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initalise UNet\n",
    "net = UNet(input_output_channels=3, hidden_channels=[64, 128, 256, 512])\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward pass\n",
    "x = torch.randn(1, 3, 32, 32)\n",
    "y = net(x)\n",
    "\n",
    "assert x.shape == y.shape\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AutoTranslateNet\n",
    "\n",
    "The AutoTranslateNet is an implementation of the network seen in\n",
    "'Semi-Supervised Raw-to-Raw mapping' https://arxiv.org/pdf/2106.13883\n",
    "\n",
    "The network consists of two auto-encoders, one for the digital domain and\n",
    "one for the film domain.\n",
    "\n",
    "There is then a translation network that is trained to map the latent space\n",
    "of the source domain auto-encoder to the latent space of the target domain\n",
    "auto-encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise `AutoTranslateNet`\n",
    "net = AutoTranslateNet(input_output_channels=3, hidden_channels=[64, 128, 256, 512])\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward pass\n",
    "film = torch.randn(1, 3, 32, 32)\n",
    "digital = torch.randn(1, 3, 32, 32)\n",
    "paired = (torch.randn(1, 3, 32, 32), torch.randn(1, 3, 32, 32))\n",
    "\n",
    "(\n",
    "    digital_reconstructed,\n",
    "    film_reconstructed,\n",
    "    digital_to_film,\n",
    "    film_to_digital,\n",
    "    paired_encoder_representations,\n",
    ") = net(digital, film, paired)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hydra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in [\"ffnn\", \"conv\", \"unet\", \"auto-translate\"]:\n",
    "        with initialize(version_base=None, config_path=\"../configs/model/net\", job_name=\"nets\"):\n",
    "                cfg = compose(config_name=model)\n",
    "                net = instantiate(cfg)\n",
    "                print(f\"âœ… Loaded {cfg._target_}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sillystill",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
