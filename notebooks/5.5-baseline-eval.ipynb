{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison to Baselines\n",
    "\n",
    "In this notebook, we calculate evaluation metrics only comparing digital to film.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autorootcwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "from torchmetrics import MetricCollection\n",
    "from torchmetrics.image import (\n",
    "    StructuralSimilarityIndexMeasure as SSIM,\n",
    "    PeakSignalNoiseRatio as PSNR,\n",
    ")\n",
    "\n",
    "from torchmetrics.image.lpip import LearnedPerceptualImagePatchSimilarity as LPIPS\n",
    "from src.eval import PieAPP\n",
    "from src.data.components import PairedDataset\n",
    "from src.models import transforms as CT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infer_metrics = MetricCollection(\n",
    "    {\n",
    "        \"ssim\": SSIM(),\n",
    "        \"psnr\": PSNR(),\n",
    "        \"lpips\": LPIPS(),\n",
    "        \"pieapp\": PieAPP(),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "RAW_DIR = os.getcwd()\n",
    "DATA_DIR = os.path.join(RAW_DIR, 'data')\n",
    "SUBSET = False\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No Alteration\n",
    "\n",
    "We compute metrics on simply predicting the film image as the digital image. I.e. we compute metrics over the (digital, film) pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "film_paired_dir = os.path.join(DATA_DIR, \"paired\", \"processed\", \"film\")\n",
    "digital_paired_dir = os.path.join(DATA_DIR, \"paired\", \"processed\", \"digital\")\n",
    "digital_film_data = PairedDataset(image_dirs=(film_paired_dir, digital_paired_dir))\n",
    "film_0, digital_0 = digital_film_data[0]\n",
    "if SUBSET:\n",
    "    digital_film_data = Subset(digital_film_data, range(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the first example and compute its metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_infer(img):\n",
    "    height = CT.get_valid_dim(img.size[1], downsample=4)\n",
    "    width = CT.get_valid_dim(img.size[0], downsample=4)\n",
    "    img_transform = CT.TestTransforms(dim=(height, width))\n",
    "    img = img_transform(img).unsqueeze(0).clamp(0+1e-5, 1-1e-5)\n",
    "    return img.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "film_0, digital_0 = digital_film_data[0]\n",
    "metrics = {k: float(v) for k, v in infer_metrics(to_infer(digital_0), to_infer(film_0)).items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now iterate over all the images in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics = {}\n",
    "for film, digital in tqdm(digital_film_data):\n",
    "    film, digital = to_infer(film), to_infer(digital)\n",
    "    metrics = infer_metrics(film, digital)\n",
    "    for metric in metrics:\n",
    "        if metric not in all_metrics:\n",
    "            all_metrics[metric] = []\n",
    "        score = metrics[metric]\n",
    "\n",
    "        if isinstance(score, torch.Tensor):\n",
    "            score = score.item()\n",
    "\n",
    "        all_metrics[metric].append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average the metrics\n",
    "mean_metrics = {k: sum(v) / len(v) for k, v in all_metrics.items()}\n",
    "mean_metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sillystill",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
