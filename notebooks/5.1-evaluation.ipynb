{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üîç Evaluation\n",
    "\n",
    "This notebook uses perceptual similarity metrics to evaluate how closely our model was able to reproduce the affect of Cinestill 800T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup\n",
    "\n",
    "---\n",
    "\n",
    "Let's install some necessary dependencies and set global variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autoroot\n",
    "import autorootcwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "\n",
    "import os\n",
    "\n",
    "# Imports\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Local modules\n",
    "from src.data.components.paired import PairedDataset\n",
    "from src.utils.utils import undo_transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pieapp - batching works\n",
    "from src.eval import PieAPP\n",
    "\n",
    "app = PieAPP()\n",
    "x, y = torch.rand(2, 3, 256, 256), torch.rand(2, 3, 256, 256) # fake data\n",
    "app.update(x, y)\n",
    "print(app.compute())\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pieapp - batching works\n",
    "app = PieAPP()\n",
    "app.update(x[0].unsqueeze(0), y[0].unsqueeze(0))\n",
    "app.update(x[1].unsqueeze(0), y[1].unsqueeze(0))\n",
    "print(app.compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sim-dist works\n",
    "from src.eval import PieAPP\n",
    "\n",
    "app = PieAPP()\n",
    "app.update(x, x)\n",
    "app.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.eval import FID\n",
    "\n",
    "fid = FID()\n",
    "x, y = torch.rand(2, 3, 256, 256), torch.rand(2, 3, 256, 256) # fake data\n",
    "fid.update(x, y)\n",
    "fid.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the `PairedDataset`\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "RAW_DIR = os.getcwd()\n",
    "DATA_DIR = os.path.join(RAW_DIR, 'data')\n",
    "# Instantiate paths\n",
    "film_paired_dir = os.path.join(DATA_DIR, \"paired\", \"processed\", \"film\")\n",
    "digital_paired_dir = os.path.join(DATA_DIR, \"paired\", \"processed\", \"digital\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate dataset\n",
    "digital_film_data = PairedDataset(\n",
    "    image_dirs=(film_paired_dir, digital_paired_dir),\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Loaded {len(digital_film_data)} paired samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect samples\n",
    "film, digital = digital_film_data[0]\n",
    "print(f\"Film image: {film.shape}, Digital image {digital.shape}\")\n",
    "\n",
    "print(type(film), type(digital))\n",
    "\n",
    "# Show sample\n",
    "fig, axs = plt.subplots(ncols=2, figsize=(8, 4))\n",
    "axs[0].imshow(undo_transforms(film).numpy())\n",
    "axs[1].imshow(undo_transforms(digital).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make sure we have Tensors to give to the Eval Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(film), type(digital))\n",
    "print(type(film.unsqueeze(0)), type(digital.unsqueeze(0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try using our Evaluation Metrics\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.eval.pie_app import PieAPPMetric\n",
    "\n",
    "x = film.unsqueeze(0)\n",
    "y = digital.unsqueeze(0)\n",
    "\n",
    "metric = PieAPPMetric()\n",
    "\n",
    "metric.update(x, x)\n",
    "loss: torch.Tensor = metric.compute()\n",
    "print(f\"PieAPP loss: {loss:0.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define metrics\n",
    "from torchmetrics import MetricCollection\n",
    "from src.eval import SSIM, PSNR, LPIPS, PieAPP\n",
    "\n",
    "\n",
    "metrics = MetricCollection(\n",
    "    {\n",
    "        \"ssim\": SSIM(),\n",
    "        \"psnr\": PSNR(),\n",
    "        \"lpips\": LPIPS(),\n",
    "        \"pieapp\": PieAPP(),\n",
    "    }\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sillystill",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
