{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autorootcwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import os\n",
    "from torchmetrics import MetricCollection\n",
    "from torchmetrics.image import (\n",
    "    StructuralSimilarityIndexMeasure as SSIM,\n",
    "    PeakSignalNoiseRatio as PSNR,\n",
    ")\n",
    "from src.data.components import PairedDataset\n",
    "from torch.utils.data import Subset\n",
    "from torchmetrics.image.lpip import LearnedPerceptualImagePatchSimilarity as LPIPS\n",
    "from src.eval import PieAPP\n",
    "from tqdm import tqdm\n",
    "from src.models import transforms as CT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = MetricCollection(\n",
    "    {\n",
    "        \"ssim\": SSIM(),\n",
    "        \"psnr\": PSNR(),\n",
    "        \"lpips\": LPIPS(),\n",
    "        \"pieapp\": PieAPP(),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define 2 pairs of random tensors at different sizes\n",
    "x = torch.ones(1, 3, 64, 64)\n",
    "y = x + 0.1 * torch.randn_like(x)\n",
    "x2 = torch.ones(1, 3, 256, 256)\n",
    "y2 = x2 + 0.1 * torch.randn_like(x2)\n",
    "\n",
    "# Print smaller image metrics\n",
    "print(\"Metrics for smaller images\")\n",
    "print(metrics(x, y))\n",
    "\n",
    "# Print larger image metrics\n",
    "print(\"Metrics for larger images\")\n",
    "print(metrics(x2, y2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "RAW_DIR = os.getcwd()\n",
    "DATA_DIR = os.path.join(RAW_DIR, 'data')\n",
    "\n",
    "film_paired_dir = os.path.join(DATA_DIR, \"paired\", \"processed\", \"film\")\n",
    "digital_paired_dir = os.path.join(DATA_DIR, \"paired\", \"processed\", \"digital\")\n",
    "digital_film_data = PairedDataset(image_dirs=(film_paired_dir, digital_paired_dir))\n",
    "film_0, digital_0 = digital_film_data[0]\n",
    "digital_film_subset = Subset(digital_film_data, range(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_valid_dim(dim: int, downsample: int = 1) -> int:\n",
    "    \"\"\"\n",
    "    Returns the nearest multiple of 8 that is less than or equal to the\n",
    "    input dimension. This is required because of the network architecture.\n",
    "\n",
    "    Args:\n",
    "        dim (int): The input dimension\n",
    "\n",
    "    Returns:\n",
    "        int: The nearest multiple of 4 that is less than or equal to the input\n",
    "    \"\"\"\n",
    "    adjusted_dim = dim // downsample\n",
    "    valid_dim = (adjusted_dim // 8) * 8\n",
    "    return valid_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "downsample = [12, 16, 32]\n",
    "\n",
    "all_metrics = {}\n",
    "for i, (film, digital) in enumerate(tqdm(digital_film_data)):\n",
    "    for sample in downsample:\n",
    "        height = CT.get_valid_dim(film.size[1], downsample=sample)\n",
    "        width = CT.get_valid_dim(film.size[0], downsample=sample)\n",
    "        film_transform = CT.TestTransforms(dim=(height, width))(film)\n",
    "        digital_transform = CT.TestTransforms(dim=(height, width))(digital)\n",
    "        film_transform = film_transform.unsqueeze(0)\n",
    "        digital_transform = digital_transform.unsqueeze(0)\n",
    "        results = metrics(film_transform, digital_transform)\n",
    "        for metric, score in results.items():\n",
    "            all_metrics.setdefault(metric, {}).setdefault(sample, []).append(score)\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "print(\"Mean scores for each down sample level as a pandas DataFrame\")\n",
    "mean_scores = {}\n",
    "for metric, scores in all_metrics.items():\n",
    "    mean_scores[metric] = {}\n",
    "    for sample, sample_scores in scores.items():\n",
    "        mean_scores[metric][sample] = np.mean(sample_scores)\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(mean_scores, index=downsample, columns=all_metrics.keys())\n",
    "print(df)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sillystill",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
